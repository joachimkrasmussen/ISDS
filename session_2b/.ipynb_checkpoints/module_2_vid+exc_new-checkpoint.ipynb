{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Exercises for Section 2: Data Structuring\n",
    "\n",
    "In this combined teaching module and exercise set you will be working with structuring data. \n",
    "\n",
    "We will start out with some material about how write readable code. \n",
    "\n",
    "Then we will focus on data cleaning, in particular working with pandas data types and new data types:\n",
    "1. String  data\n",
    "1. Categorical data\n",
    "1. Temporal data\n",
    "1. Missing data and duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "## Packages\n",
    "But first... load in the required modules and set up the plotting library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome (Back to) Pandas\n",
    "\n",
    "As mentioned during the lecture, data structuring skills are necessary to become a great data scientist. There is no way around it. \n",
    "\n",
    "Let's start with the basics. In the following video, we start with talking about the fundamentals of Pandas: The Pandas DataFrame and the Pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "In this set of introductory exercises, we are going use some of the tools from the video. Be aware that there is going to be some repition of the content from assignment 0 here - but these things are all very useful to get under your skin!\n",
    "\n",
    "First, run the following two lines below. What did the second line do? What was the first? Try and change the seed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=161193)\n",
    "np_arr=np.random.rand(4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, generate a Pandas DataFrame called `my_df` from `np_arr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_df = \n",
    "### BEGIN SOLUTION\n",
    "my_df = pd.DataFrame(np_arr)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue working with this DataFrame, we want to make sure that you are capable of transforming them back to different types of containers. \n",
    "\n",
    "In the following part, generate an `array`, a `list` of lists and a `dict` from `my_df`. \n",
    "\n",
    "You should be able to do each of these things in one line. Verify that you did this properly by printing your output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_arr = \n",
    "# my_list = \n",
    "# my_dict =\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "my_arr = my_df.values\n",
    "my_dict = my_df.to_dict()\n",
    "my_list = my_df.values.tolist()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the DataFrame, we want you to try the following: \n",
    "1. label the columns `col1`, `col2` and `col3`\n",
    "2. change the indices to Roman numerals\n",
    "\n",
    "Display `my_df` after having made these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.392853</td>\n",
       "      <td>0.027592</td>\n",
       "      <td>0.150674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ii</th>\n",
       "      <td>0.328318</td>\n",
       "      <td>0.510783</td>\n",
       "      <td>0.870753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iii</th>\n",
       "      <td>0.102371</td>\n",
       "      <td>0.360334</td>\n",
       "      <td>0.169993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iv</th>\n",
       "      <td>0.232413</td>\n",
       "      <td>0.575514</td>\n",
       "      <td>0.322596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         col1      col2      col3\n",
       "i    0.392853  0.027592  0.150674\n",
       "ii   0.328318  0.510783  0.870753\n",
       "iii  0.102371  0.360334  0.169993\n",
       "iv   0.232413  0.575514  0.322596"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "cols = ['col1', 'col2', 'col3']\n",
    "indx = ['i', 'ii', 'iii', 'iv'] \n",
    "my_df.columns=cols\n",
    "my_df.index=indx\n",
    "### END SOLUTION\n",
    "\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to go back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i      0.027592\n",
       "ii     0.510783\n",
       "iii    0.360334\n",
       "iv     0.575514\n",
       "Name: col2, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "my_ser = my_df['col2']\n",
    "### END SOLUTION\n",
    "\n",
    "my_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39285338, 0.02759191, 0.15067405],\n",
       "       [0.32831842, 0.51078339, 0.87075339],\n",
       "       [0.10237089, 0.36033395, 0.16999285],\n",
       "       [0.23241257, 0.57551393, 0.32259622]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "my_arr2 = my_df.values\n",
    "### END SOLUTION\n",
    "\n",
    "my_arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col1': {'i': 0.39285337677233134,\n",
       "  'ii': 0.3283184207598464,\n",
       "  'iii': 0.1023708897883584,\n",
       "  'iv': 0.23241256793283005},\n",
       " 'col2': {'i': 0.027591907203866506,\n",
       "  'ii': 0.5107833872168315,\n",
       "  'iii': 0.36033394924487483,\n",
       "  'iv': 0.5755139315316452},\n",
       " 'col3': {'i': 0.15067405305203407,\n",
       "  'ii': 0.8707533892846663,\n",
       "  'iii': 0.1699928508058457,\n",
       "  'iv': 0.3225962164459285}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "my_dict = my_df.to_dict()\n",
    "### END SOLUTION\n",
    "\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment on Readable Code\n",
    "\n",
    "If we have lots of code it may be very difficult for others or ourselves to read. Therefore, providing some structure and meta text can help reading the code.\n",
    "\n",
    "\n",
    "## Commenting\n",
    "\n",
    "When making code it's good practice to document different parts of the code. In particular describing functions and complex code. The example below shows how to make multi-line comments (as a string, which is not assigned) and in-line comments using the `#` character.\n",
    "\n",
    "```python\n",
    "def my_fct(x,y):\n",
    "    ''' \n",
    "    Computes the sum of input values (multi-line comment as string)\n",
    "    '''\n",
    "    z = x+y # Here we perform the summation (in-line comment)\n",
    "    return z\n",
    "```\n",
    "\n",
    "\n",
    "## Method chaining\n",
    "\n",
    "We can write multiple operations together by putting them one after the other, which is known as `method chaining`. Using this, we only need to assign them once to a new object and therefore we save a lot of code. We change the example below into one using a method chain:\n",
    "\n",
    "Example without method chain\n",
    "```python\n",
    "df_temp1 = df.loc[selection]\n",
    "df_temp2 = df_temp1.sort_values(by=X)\n",
    "df_out = df_temp2.reset_index()\n",
    "```\n",
    "\n",
    "Example with method chain - one line\n",
    "\n",
    "```python\n",
    "df_out = df.loc[selection].sort_values(by=X).reset_index()\n",
    "```\n",
    "As seen in the example, although using less code, our method chain will get more and more difficult to read if we include two or more operations. We can overcome this problem of long chains by splitting into multiple lines with line breaks:\n",
    "\n",
    "Example with method chain - line break\n",
    "```python\n",
    "df_out = df\\\n",
    "        .loc[selection]\\\n",
    "        .sort_values(by=X)\\\n",
    "        .reset_index()\n",
    "```\n",
    "\n",
    "Note that the backslash allows us to make a visual line break, but the code is read as one line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather data structuring - part 2\n",
    "\n",
    "We continue with the exercise that analyzes NOAA data. The first part was Assignment Part 0.4. The last part will come in Exercise Section 5.2. We start out reviewing what we did in Assignment 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.1.1:** The code below runs through all the steps we completed in Assignment 0.4 step by step. Your task is to document this code in your own words. You should also make your own annotation of parts. You should also make the code more readable by applying method chaining.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def load_weather(year):\n",
    "    \n",
    "    url = f\"ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/{year}.csv.gz\"\n",
    "\n",
    "    df_weather = pd.read_csv(url, \n",
    "                             header=None)        \n",
    "\n",
    "\n",
    "    df_weather = df_weather.iloc[:,:4] \n",
    "    \n",
    "    column_names = ['station', 'datetime', 'obs_type', 'obs_value']\n",
    "    df_weather.columns = column_names \n",
    "    \n",
    "    df_weather['obs_value'] = df_weather['obs_value'] / 10 \n",
    "    \n",
    "    \n",
    "    selection_tmax = df_weather.obs_type == 'TMAX'\n",
    "    df_select = df_weather.loc[selection_tmax]\n",
    "    \n",
    "    df_sorted = df_select.sort_values(by=['station', 'datetime'])\n",
    "    df_reset = df_sorted.reset_index(drop=True)\n",
    "    df_out = df_reset.copy()\n",
    "            \n",
    "    \n",
    "    return df_out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>datetime</th>\n",
       "      <th>obs_type</th>\n",
       "      <th>obs_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE00135039</td>\n",
       "      <td>18630102</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGE00135039</td>\n",
       "      <td>18630103</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGE00135039</td>\n",
       "      <td>18630105</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGE00135039</td>\n",
       "      <td>18630106</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGE00135039</td>\n",
       "      <td>18630107</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>USW00014838</td>\n",
       "      <td>18630727</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>USW00014838</td>\n",
       "      <td>18630728</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5877</th>\n",
       "      <td>USW00014838</td>\n",
       "      <td>18630729</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5878</th>\n",
       "      <td>USW00014838</td>\n",
       "      <td>18630730</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>29.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5879</th>\n",
       "      <td>USW00014838</td>\n",
       "      <td>18630731</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5880 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          station  datetime obs_type  obs_value\n",
       "0     AGE00135039  18630102     TMAX       11.5\n",
       "1     AGE00135039  18630103     TMAX       11.0\n",
       "2     AGE00135039  18630105     TMAX       15.5\n",
       "3     AGE00135039  18630106     TMAX       16.5\n",
       "4     AGE00135039  18630107     TMAX       15.0\n",
       "...           ...       ...      ...        ...\n",
       "5875  USW00014838  18630727     TMAX       20.6\n",
       "5876  USW00014838  18630728     TMAX       19.9\n",
       "5877  USW00014838  18630729     TMAX       25.1\n",
       "5878  USW00014838  18630730     TMAX       29.4\n",
       "5879  USW00014838  18630731     TMAX       25.6\n",
       "\n",
       "[5880 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.1]\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "import pandas as pd # Import pandas package\n",
    "\n",
    "def load_weather(year):\n",
    "    \n",
    "    url = f\"ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/{year}.csv.gz\"\n",
    "\n",
    "    # Load the data\n",
    "    df_weather = pd.read_csv(url, header=None)\\\n",
    "                             .iloc[:,:4]\n",
    "    \n",
    "    # Structure and clean data using methods chaining\n",
    "    df_out = df_weather\\\n",
    "                .rename(columns = {0: 'station', 1: 'datetime', 2: 'obs_type', 3: 'obs_value'})\\\n",
    "                .query(\"obs_type == 'TMAX'\")\\\n",
    "                .assign(obs_value = lambda df: df['obs_value']/10)\\\n",
    "                .sort_values(by=['station', 'datetime'])\\\n",
    "                .reset_index(drop=True)\\\n",
    "                .copy()\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "load_weather(1863)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data types\n",
    "\n",
    "## String data\n",
    "We will proceed with learning about processing string data. We have already seen this in Python (session). See the video with a short recap and how we do things in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('bMGRna-iLFM', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.1.2:** Load the data for year 1864. Extract the area code (country and state) from the station name into a separate column.\n",
    "\n",
    "> _Hint:_ The station column contains a GHCND ID, given to each weather station by NOAA. The format of these ID's is a 2 letter country/state code, followed by possible additional information on the third character and then an integer identifying the specific station. A simple approach is to assume a fixed length of the country ID. A more complex way would be to use the [`re`](https://docs.python.org/3.8/library/re.html) module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data\n",
    "\n",
    "Watch the video below introducing categorical data and how to work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('qGAYwb8NHPE', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.1.3:** \n",
    "Convert the `area` column to a categorical variable. \n",
    "Transform the `obs_value` column from a continuous to a categorical variable by partitioning it into `3` intervals. Call this new column for `obs_value_cat`.  This can be done using the `pd.cut()` method of pandas. \n",
    "Make another column with  `obs_value` as a categorical variable but this time label the 3 intervals as `[\"cold\", \"medium\", \"hot\"]`. This can be done by specifying the `labels` parameter in the `pd.cut()` method of pandas. Call this new column for `obs_value_cat_labeled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal data\n",
    "\n",
    "Our coverage of basic Python did not include time. This is another elementary datatypes, that has its own native structure or maybe converted to an integer using a smart method. See more below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('BGnxa6mT94g', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.1.4:** Convert the date formatted as string to datetime. Call this column `datetime_dt`. Make a new column named `month` with the month for each observation. Set the datetime variable as temporal index. \n",
    "\n",
    "> Hint: Look up `.set_index()` setting the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.1.5:** Update your annotated function above with processing of area and temporal data.          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.1.6:** Make a timeseries plot for the stations called `AU000005901`.\n",
    "\n",
    "> _Hint:_ for this you need to know a few methods of the pandas Series objects. `.plot()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Working with US census data\n",
    "\n",
    "In this section we will use [this dataset](https://archive.ics.uci.edu/ml/datasets/Adult) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.html) to practice some basic operations on pandas dataframes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.2.1:** This link `'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'` leads to a comma-separated file with income data from a US census. Load the data into a pandas dataframe and show the 25th to 35th row.\n",
    "\n",
    "> _Hint 1:_ There are no column names in the dataset. Use the list `['age','workclass', 'fnlwgt', 'educ', 'educ_num', 'marital_status', 'occupation','relationship', 'race', 'sex','capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'wage']` as names. \n",
    "\n",
    "> _Hint 2:_ When you read in the csv, you might find that pandas includes whitespace in all of the cells. To get around this include the argument `skipinitialspace = True` to `read_csv()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.2.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Missing data\n",
    "\n",
    "Often our data having information missing, e.g. one row lacks data on education for a specific person. Watch the video below about missing data type and get some simple tools to deal with the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('GDaxQig-qCU', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.2.2:** What is the missing value sign in this dataset? Replace all missing values with NA's understood by pandas. Then proceed to drop all rows containing any missing values with the `dropna` method. How many rows are removed in this operation?\n",
    "\n",
    "> _Hint 1:_ if this doesn't work as expected you might want to take a look at the hint for 4.2.1 again.\n",
    " \n",
    "> _Hint 2:_ The NaN method from NumPy might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.2.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Duplicated data\n",
    "\n",
    "Watch the video below about duplicated data - in particular duplicated rows and how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('BLLQofon9Ug', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.2.3:** Determine whether or not duplicated rows is a problem in the NOAA weather data and the US census data in the module. You should come up with arguments from the structure of the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.2.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Overview of data types\n",
    "\n",
    "Watch the video below about duplicated data - in particular duplicated rows and how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('mohBV7crmsU', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Additional exercises\n",
    "\n",
    "> **_Note_**: to solve the bonus exercises below, you will need to apply the `.groupby()` method a few times. This has not yet been covered in the lectures (you will see it in on of the next lectures).  \n",
    ">\n",
    "> `.groupby()` is a method of pandas dataframes, meaning we can call it like so: `data.groupby('colname')`. The method groups your dataset by a specified column, and applies any following changes within each of these groups. For a more detailed explanation see [this link](https://www.tutorialspoint.com/python_pandas/python_pandas_groupby.htm). The [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html) might also be useful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.2.4:** (_Bonus_) Is there any evidence of a gender-wage-gap in the data? Create a table showing the percentage of men and women earning more than 50K a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.2.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.2.5:** (_Bonus_) Group the data by years of education (`educ_num`) and marital status. Now plot the share of individuals who earn more than 50K for the two groups 'Divorced' and 'Married-civ-spouse' (normal marriage). Your final result should look like this: \n",
    "\n",
    "![](examplefig.png)\n",
    "\n",
    "> _Hint:_ remember the `.query()` method is extremely useful for filtering data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.2.5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
